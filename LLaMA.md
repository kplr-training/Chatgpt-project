## LLaMA – Large Language Model Meta AI

## 1- Introduction

LLaMA – Large Language Model Meta AI – est un modèle de langage développé par Meta, qui est, comme son nom l’indique, un modèle linguistique. Il s’agit du socle permettant d’utiliser les intelligences artificielles comme ChatGPT et les autres agents conversationnels.

LLaMA utilise une architecture de réseau de neurones récurrents (RNN) pour apprendre à prédire la probabilité de la prochaine séquence de mots dans un texte.

Il a été entraîné sur une grande quantité de données textuelles, ce qui lui permet de générer des phrases globalement cohérentes et naturelles.

LLaMA est donc l’équivalent de GPT-3, le modèle qui permet à ChatGPT de fonctionner, et de LaMDA, le modèle de langage développé par Google pour alimenter Bard.

## 2- C’est quoi un modèle de langage ?

Un modèle de langage est un algorithme d’apprentissage qui permet aux machines de comprendre et de générer du langage naturel.

Plus précisément, un modèle de langage est une fonction mathématique qui prend en entrée une séquence de mots et qui prédit la probabilité de la prochaine séquence de mots dans un texte.

Les modèles de langage sont entraînés sur de grandes quantités de données textuelles afin de leur permettre de prédire avec précision le mot suivant dans une phrase ou dans un texte.

Les dernières générations de LLM contiennent des milliards de paramètres, ce qui a permis d’affiner les réponses de ChatGPT et de faire en sorte que ces réponses paraissent les plus naturelles possible, comme si l’internaute échangeait avec un autre humain. 

Ils sont utilisés dans de nombreuses applications de traitement du langage naturel, telles que la génération de texte, la traduction automatique, la reconnaissance de la parole et l’analyse de sentiment.

## 3- Quelles sont ses fonctionnalités ?

LLaMA disposerait globalement des mêmes fonctionnalités que ChatGPT, à savoir :

- Génération automatique de texte
- Capacité à échanger et à tenir une discussion cohérente
- Réaliser des résumés de texte
- Il propose de plus – et il s’agit là d’une fonctionnalité mise en avant par Zuckerberg lui-même – de construire des raisonnements mathématiques et de prédire des structures protéiques.

## 4- Quelles caractéristiques pour LLaMA de Meta ?

LLaMA a pour particularité de ne fonctionner « que » sur 65 milliards de paramètres. C’est moins que ses rivaux, mais selon Meta, ce dimensionnement moindre serait pourtant un avantage : LLaMA est disponible en plusieurs versions (65 milliards de paramètres, et d’autres sur 33 milliards, 13 milliards et 7 milliards).

Meta a noté que les modèles plus petits, comme LLaMA, sont intéressants dans le monde des modèles très large, car ils demandent beaucoup moins de puissance de calcul et de ressources. Une taille réduite démocratiserait l’accès aux modèles de langage et d’épargner de la capacité de traitement.

Mais selon Meta, cette relative petitesse au niveau des paramètres ne l’empêche pas d’être « plus performant » que d’autres modèles plus grands. 

Le papier de recherche publié pour accompagner le lancement du modèle indique ainsi que *« LLaMA-13B surpasse GPT-3 sur la plupart des critères, et LLaMA-65B est compétitif avec les meilleurs modèles, Chinchilla 70B et PaLM-540B » — il s’agit de modèles développés respectivement par DeepMind, l’entreprise à l’origine d’AlphaGo, et par Google.

Son objectif serait donc d’accompagner les chercheurs et de leur offrir un réel soutien lors de la réalisation de leurs travaux de recherche.

Pour l’instant, contrairement à Chat-GPT, LLaMA n’est pas accessible à tout le monde : seuls quelques chercheurs en faisant la demande peuvent avoir accès au modèle, dont les facultés resteront à mettre à l’épreuve.

Contrairement à GPT-3, Meta n'a utilisé que des données accessibles publiquement ce qui permettrait de rendre le modèle open-source.

## 5- Les avantages de LLaMA

Voici les avantages que présentent Llama en tant qu’IA : 

- Ses ressources moindres
- Sa rigueur
- Elle est Open Source
- Accès limité

**Des ressources moindres**

- LLaMA demande des ressources bien moins importantes pour fonctionner que beaucoup de modèles concurrents, pour une efficacité souvent égale, voire supérieure.

- À titre d’exemple, on peut citer la version LlaMA-13B, qui surpasse GPT-3 et la version LlaMA-65B, qui obtient de meilleurs résultats que Chinchilla70B et PaLM-540B, alors que ce sont pourtant d’excellents modèles.

- Sa vitesse de calcul s’en trouve donc augmentée.

**Une grande rigueur**

- Des études, citées par Meta dans son document de recherche détaillé, montrent que pour perfectionner l’IA, il est plus efficace d’avoir recours à des petits modèles entraînés sur de nombreuses données précises que d’utiliser de grands modèles aux multiples paramètres qui n’ont pas été suffisamment entraînés. 

- Cela permet en effet de gagner en rigueur en réduisant le nombre d’erreurs et d’approximations. 

**Llama fonctionne en open source**

- Si les jeux de données utilisés par LLaMA sont moins fournis que ceux de ses concurrents, c’est parce que Meta a fait le choix de n’utiliser que des données publiques. 

- Elles sont extraites à plus des deux tiers de dumps de Common Crawl, de corpus de livres (projet Gutenberg et un sous-ensemble de The Pile), de données scientifiques (ArXiv), de base de questions-réponses (StackExchange) et du jeu de données GitHub public disponible sur BigQuery. 

- L’entreprise a fait savoir sa volonté de créer un modèle open-source afin qu’un maximum de chercheurs puissent travailler sur ce modèle et l’enrichir. 

**Accès limité**

- Le but de Meta n’est pas – pour le moment du moins – de commercialiser LLAMAl pour des plateformes tierces ou de le rendre accessible au grand public.

- L’entreprise a clairement affiché sa volonté de faciliter la recherche scientifique. Seuls les chercheurs et chercheuses , issus du public ou de la société civile, sélectionnés sur le volet par l’entreprise, auront ainsi le privilège d’utiliser cet outil.  

- Rappelez que ChatGBT et Bard ont été utilisés à mauvais escient à par des internautes malveillants pour créer du contenu toxique ou des logiciels malveillants.

## 6- C'est quoi LLaMA CPP ?

Llama CPP est un instrument permettant de mettre en œuvre des modèles linguistiques tels que LLaMA, Alpaca et GPT4All en C/C++ pur.

Llama CPP est adapté à divers systèmes d’exploitation, dont Mac OS, Linux et Windows (via CMake). Il est aussi opérationnel dans un environnement Docker. Il permet l’utilisation de plusieurs modèles linguistiques, notamment :

- LLaMA
- Alpaca
- GPT4All
- Chinese LLaMA / Alpaca
- Vigogne (français)

Une fois Llama CPP compilé et les poids des modèles d’origine obtenus, l’instrument peut servir à convertir et quantifier les modèles. Il est également utilisable en mode interactif pour une expérience semblable à ChatGPT.

## 7- C'est quoi ALPACA?

Alpaca est un modèle de langage qui reproduit les capacités du GPT-3.5 d’OpenAI. Créé par des chercheurs de Stanford à partir du modèle LLaMA de Meta.

Dans leur travail, le groupe de Stanford a utilisé les instructions générées par l’intelligence artificielle pour entraîner Alpaca 7B, un modèle de langage que les chercheurs disent présenter de nombreux comportements similaires à ceux du modèle text-davinci-003 d’OpenAI. 

Dans un test à l’aveugle utilisant des entrées provenant du Self-Instruct Evaluation Set, les deux modèles ont obtenu des performances comparables selon l’équipe.

